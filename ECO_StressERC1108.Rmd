---
title: "Between- & Within- Person Stress Predicts Emotion Regulation Initiation: The Role of controllability and Cognitive Resource"
author: "Mengzhe Wei, Angie Gross, Tammy English"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: journal
    toc: yes
    toc_float:
      collapsed: true
---

# ECO Stress and ER Choice Analysis
Notes: Started 08 Nov 2024 by Mengzhe Wei to run analysis looking at ER Initiation based on stress.
Within person (level 1): stress level in EMA, controllability
Between person (level 2): MCI status (young, CN, MCI)
Outcome variables: 
Whether participant chose to initiate ER

```{r setup, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
# Set up packages and upload data. 
rm(list=ls());
options(warnPartialMatchDollar=TRUE);   # safety option
library(lubridate); library(lme4); library(knitr); library(RColorBrewer); library (kableExtra);library(correlation); library(tidyverse); library(psych); library(data.table);library(lmerTest);library(performance);library(car);library(gridExtra);library(glmmTMB); library(parameters)
```

## Data Quality Check

### Dataset Cleaning
```{r center, eval=TRUE, echo=FALSE, warning=FALSE, cache=FALSE, message=FALSE}
# Read in dataset
ESM_clean<-fread("ESM_clean.csv")
survey <- fread("ECO_baseline.csv")
data <-ESM_clean %>%
  group_by(PID) %>%
  mutate (Group_code = case_when(Group == 0 ~ -1,  Group == 1 ~ 0, Group == 2 ~ 1),
          Group = factor(Group_code, levels = -1:1, labels = c("YA","CN","MCI")),
          stress_pm = mean(esm_stressed,na.rm=TRUE),
          NA_pm = mean(negemotions, na.rm=TRUE),
          ER_need_pm = mean(esm_wanted_change, na.rm=TRUE),
          control_pm = mean(situation_control,na.rm=TRUE),
          ER_yes_pm = sum(ER_yes,na.rm = TRUE)/ sum(completed==1,na.rm = TRUE),
          distr_pm = ifelse(sum(ER_yes,na.rm = TRUE) > 0, sum(distr_yes,na.rm = TRUE) / sum(ER_yes,na.rm = TRUE), 0),
          min_pm = ifelse(sum(ER_yes,na.rm = TRUE) > 0, sum(min_yes,na.rm = TRUE) / sum(ER_yes,na.rm = TRUE), 0),
          reap_pm = ifelse(sum(ER_yes,na.rm = TRUE) > 0, sum(reap_yes,na.rm = TRUE) / sum(ER_yes,na.rm = TRUE), 0))%>% 
  ungroup()%>%
  mutate(
    stress_gmc = scale(esm_stressed, center = T, scale = F),
    stress_w = esm_stressed - stress_pm,
    stress_b = stress_gmc - stress_w,
    NA_gmc = scale(negemotions, center = T, scale = F),
    NA_w = negemotions - NA_pm,
    NA_b = NA_gmc - NA_w,
    control_gmc = scale(situation_control, center = T, scale = F),
    control_w = situation_control - control_pm,
    control_b = control_gmc - control_w,
    ER_need_gmc = scale (esm_wanted_change, center = T, scale = F),
    ER_need_w = esm_wanted_change -ER_need_pm,
    ER_need_b = ER_need_gmc - ER_need_w,
    CESD_gmc = scale(CES_D_sum, center = T, scale = F))%>%
  group_by(PID,day) %>%
  mutate(
    stress_lag_w = lag (stress_w,1),
    stress_lag_b =lag (stress_b,1),
    NA_lag_w =lag (NA_w,1),
    NA_lag_b = lag (NA_b,1),
    control_lag_w = lag(control_w,1),
    control_lag_b = lag(control_b,1),
    ER_need_lag_w = lag (ER_need_w,1),
    ER_need_lag_b = lag (ER_need_b,1)
  ) %>%
  ungroup() %>%
  group_by(PID) %>%
  mutate (consecutive_sum = sum(completed == 1 & !is.na(esm_stressed_lag))) %>%
  ungroup() %>%
  as.data.frame()
data_b <- data %>%
  group_by(PID) %>%
  summarise(
    Group_code=first(Group_code),
    Group = first(Group),  # Assuming all entries of a single group per PID are the same
    completed_sum = sum(completed==1,na.rm = TRUE),
    ER_yes_sum = sum(ER_yes,na.rm = TRUE),
    CES_D_sum = first(CES_D_sum),
    stress_pm = first(stress_pm),
    ER_yes_pm = first(ER_yes_pm),
    ER_need_pm = first (ER_need_pm),
    control_pm = first (control_pm),
    NA_pm = first(NA_pm),
    distr_pm = first(distr_pm),
    min_pm = first(min_pm),
    reap_pm = first(reap_pm),
    CESD_gmc = first(CESD_gmc),
    consecutive_sum = first(consecutive_sum)) %>%
  ungroup() %>%
  as.data.frame()
sum(data_b$ER_yes_sum) # the number of prompts where pt indicated that they've regulated their emotion since the last prompt / 0-1.5 hr ago.
data$Group <- relevel(data$Group, ref="MCI")
sum(data$completed == 1 & !is.na(data$esm_stressed_lag)) #data points where we have data for lagged analysis, 5640  is not bad at all
summary(data_b$consecutive_sum)
exclude_PIDs<-data_b$PID[data_b$consecutive_sum <= 5] #excluding 28 pts in this criteria; exlucding 6 in YA, 9 in CN, 13 in MCI
length(exclude_PIDs)
data_b_exclude <- data_b[!data_b$PID %in% exclude_PIDs,]
table(data_b_exclude$Group)
table(data_b$Group)
data_exclude<-data[!data$PID %in% exclude_PIDs,]
#Deal with the time variable
str(data_exclude$start_date)
df <- plyr::ddply(data_exclude, "PID", summarise,
                  startdate = min(start_date, na.rm = TRUE))
data_exclude <- left_join(data_exclude, df, by = "PID")
data_exclude$time0<- as.numeric(difftime(data_exclude$start_date, data_exclude$startdate, units = "secs"))
data_exclude$time0m <- data_exclude$time0 / 100000
```

### Check internal consistency
```{r Internal consistency, eval=TRUE, echo=TRUE, cache=FALSE, warning=FALSE, message=FALSE}
NA.composite <- select (data_exclude,c("PID", "esm_stressed","esm_lonely","esm_angry","esm_nervous","esm_fearful","esm_sad","esm_disgusted","esm_sluggish","esm_bored","esm_isolated") )
omegaSem(NA.composite, id = "PID")
```

### Data distribution and Descriptive Stats
```{r distribution,fig.width=10, fig.height=6, eval=TRUE, echo=TRUE, cache=FALSE,warning=FALSE, message=TRUE}
layout(matrix(1:8, 2,4, byrow=TRUE)); 
par(mar = c(2, 2, 2, 1), mgp = c(1.1, 0.2, 0), tcl = -0.3)
#Check distribution of all data; loop through histogram
variables <- c("completed_sum","consecutive_sum", "ER_yes_sum","CES_D_sum", "stress_pm","NA_pm", "control_pm", "ER_yes_pm")
for (vid in 1:length(variables)) { #vid<-3
  hist(data_b_exclude[[variables[vid]]], breaks = 10, border = "black",main = variables[vid], xlab = variables[vid], ylab = "Count")
}
par(mfrow = c(1, 1))
# Overall stats including centered variables
describe(data_b_exclude)
length(which(data_b_exclude$CES_D_sum>=16))
# 67 participants met the cutoff for significant depressive symptomatology
ggplot(data_b_exclude, aes(x = consecutive_sum, fill = Group)) + 
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(x = "consecutive_sum", y = "Frequency", title = "Histogram by Group") +
  theme_classic() +
  facet_wrap(~ Group) +  # Create separate plots for each group
  scale_fill_brewer(palette = "Set1")  # Optional: Use a color palette
```

### Demographics
```{r Demo, eval=TRUE, echo=TRUE,cache=FALSE, warning=FALSE, message=FALSE}
#Demo table
demo.sum <- data_exclude %>% distinct(PID, .keep_all=TRUE) %>%
  select(PID, Group, Race2_1, Race2_2, Race2_3, Race2_4, Race2_5, Race2_6, Race2_7, 
         Gender, Age)
#Group, 0=young adult, 1=CN older adults, 2=MCI older adult
demo.sum %>%
  count(Group)
#Race
demo.sum %>%
  summarise(
    African_American_Black = mean(Race2_1), 
    American_Indian_Alaskan_Native = mean(Race2_2),
    Asian_Asian_American_Pacific_Islander = mean(Race2_3),
    Middle_Eastern_Arab_American = mean(Race2_4),
    Caucasian_European_American = mean(Race2_5),
    Hispanic_Latino = mean(Race2_6),
    Other = mean(Race2_7)
  )
#Age
demo.sum %>%
  summarise(
    mean_age=mean(Age),
    sd_age=sd(Age),
    min_age=min(Age),
    max_age=max(Age)
  )
#Age group by cognitive group
demo.sum %>%
  group_by(Group) %>%
  summarise(
    mean_age=mean(Age),
    sd_age=sd(Age),
    min_age=min(Age),
    max_age=max(Age)
  )
#Gender
demo.sum %>%
  mutate (Gender = factor(Gender, levels = 0:2, labels = c("male","female","other"))) %>%
  count(Gender)
```

### intraclass correlations of EMA items
```{r EMA cor, echo=TRUE,eval=TRUE,cache=FALSE,warning=F, message=F}
fit_logit <- glmer(ER_yes ~ 1 + (1 | PID), data = data_exclude, family = binomial(link = "logit"))
model_performance(fit_logit) 
#ICC = .463,54% variance is within person
fit0 <- glmer(esm_stressed_lag ~ 1 + (1 | PID), data = data_exclude)
model_performance(fit0) 
#ICC = 0.408, 59% variance is within person
fit0 <- glmer(control_lag ~ 1 + (1 | PID), data = data_exclude)
model_performance(fit0)
```


## Correlations

### Lagged; initiation only
```{r cor, echo=TRUE,eval=TRUE,warning=F, cache=FALSE, message=F}
data_exclude$PID<-as.numeric(data_exclude$PID)
stats<-statsBy(select(data_exclude,c("PID","Group","esm_stressed_lag", "control_lag", "ER_yes")),group="PID")
#between person correlations
stats$rbg #Between-Person Correlation for Raw Scores
stats$pbg #Between-Person Correlation for Person-Mean Centered Scores
#within person correlations
stats$rwg #Within-Person Correlation for Raw Scores
stats$pwg #Within-Person Correlation for Person-Mean Centered Scores
```

## Multilevel Modeling

### Main Effect: Stress predicting overall ER use, lagged
```{r StressER,echo=TRUE,eval=TRUE,warning=F, cache=FALSE, message=F}
data_exclude$Group <- relevel(data_exclude$Group, ref="MCI")
ER <- glmer(ER_yes ~ stress_lag_w + stress_lag_b + control_lag_w + control_lag_b + 
              Group + time0m + (1 + time0m | PID), 
            family = binomial(link = "logit"),
            data = data_exclude)
summary(ER)
#As hypothesized, both within & between person stress increase the chance of ER initiation
#Within person control decreases the chance of ER initiation

#Odd ratio
model_parameters(ER, CI = 0.95, ci_method = "wald", ci_random = NULL, bootstrap = FALSE, iterations = 1000,

                 standardize = NULL, effects = "all", component = "all", group_level = FALSE,exponentiate = TRUE, p_adjust = NULL,

                 wb_component = TRUE, summary = getOption("parameters_mixed_summary", FALSE), keep = NULL, drop = NULL,

verbose = TRUE)
#Within person stress is associated with an 11% increase in the odds of initiating ER
#Between person stress is associated with an 64% increase in the odds of initiating ER
#Within person controllability is associated with an 6% decrease in the odds of initiating ER
```

### control as a moderator
```{r controlER,echo=TRUE,eval=TRUE,warning=F, cache=FALSE, message=F}
control_ER <-glmer(ER_yes ~ control_lag_w*stress_lag_w +  control_lag_b*stress_lag_w + stress_lag_b + time0m + Group + (1 + time0m | PID), 
            family = binomial(link = "logit"),
            data = data_exclude,
            control = glmerControl(optimizer = "bobyqa"))
summary(control_ER)
#N.S.
```

### Group as a moderator
```{r GroupER,echo=TRUE,eval=TRUE,warning=F, cache=FALSE, message=F}
data_exclude$Group <- relevel(data_exclude$Group, ref="MCI")
ER_MCI <- glmer(ER_yes ~ stress_lag_w*Group + stress_lag_b*Group + time0m +
              (1 + time0m | PID), 
            family = binomial(link = "logit"),
            data = data_exclude,
            control = glmerControl(optimizer = "bobyqa"))
summary(ER_MCI) 

data_exclude$Group <- relevel(data_exclude$Group, ref="YA")
ER_YA <- glmer(ER_yes ~ stress_lag_w*Group + stress_lag_b*Group + time0m +
              (1 + time0m | PID), 
            family = binomial(link = "logit"),
            data = data_exclude,
            control = glmerControl(optimizer = "bobyqa"))
summary(ER_YA) 

data_exclude$Group <- relevel(data_exclude$Group, ref="CN")
ER_CN <- glmer(ER_yes ~ stress_lag_w*Group + stress_lag_b*Group + time0m +
              (1 + time0m | PID), 
            family = binomial(link = "logit"),
            data = data_exclude,
            control = glmerControl(optimizer = "bobyqa"))
summary(ER_CN) 
#Younger adults initiate less ER compared to MCI adults in the simpler model, but not the model where everything's included.

```

```{r mod graphs, echo=TRUE, eval=TRUE, fig.width=10, fig.height=8, warning=F, cache=FALSE, message=F}
ef <- effects::effect(term="stress_lag_w:Group", mod=ER_MCI)
efdata<-as.data.frame(ef) #convert the effects list to a data frame
efdata$Group<-as.factor(efdata$Group)
g0w<-ggplot(efdata, aes(x=stress_lag_w, y=fit, color=Group,group=Group)) +
    geom_point() +
    geom_line(size=1.2) +
    geom_ribbon(aes(ymin=fit-se, ymax=fit+se, fill=Group),alpha=0.3) +
    labs(x= "stress_lag_w", y="ER Use", color="Group", fill="Group") +
    theme_classic() + theme(text=element_text(size=12)) +
    scale_y_continuous(breaks = seq(0, 1, by=0.2), limits=c(0,1)) +
    scale_x_continuous(breaks = seq(-5.5, 6, by=2), limits=c(-5.5, 6))
g0w
#grid.arrange(g0w,g1w, ncol=2)
```
